"""
Malware Hash Checker Tool

This tool checks file hashes against multiple threat intelligence sources
and malware databases to identify potential threats.
"""

import re
import hashlib
import random
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple

try:
    from .schemas import (
        MalwareHashInput, MalwareHashOutput, ThreatIntelligenceResult,
        MalwareMetadata, ReputationAnalysis, HashValidation
    )
except ImportError:
    from schemas import (
        MalwareHashInput, MalwareHashOutput, ThreatIntelligenceResult,
        MalwareMetadata, ReputationAnalysis, HashValidation
    )


class MalwareHashChecker:
    """Malware hash checker with multiple threat intelligence sources"""
    
    # Hash type patterns
    HASH_PATTERNS = {
        'md5': r'^[a-fA-F0-9]{32}$',
        'sha1': r'^[a-fA-F0-9]{40}$',
        'sha256': r'^[a-fA-F0-9]{64}$',
        'sha512': r'^[a-fA-F0-9]{128}$'
    }
    
    # Known malicious hash samples (for demonstration)
    KNOWN_MALICIOUS_HASHES = {
        # WannaCry samples
        '84c82835a5d21bbcf75a61706d8ab549': 'wannacry',
        'ed01ebfbc9eb5bbea545af4d01bf5f1071661840480439c6e5babe8e080e41aa': 'wannacry',
        
        # Conficker samples  
        'b7c1e8c4f7b8e5c8e1f7b8e5c8e1f7b8': 'conficker',
        
        # Zeus samples
        '5f4c4f7b8e5c8e1f7b8e5c8e1f7b8e5c': 'zeus',
        
        # Emotet samples
        'a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6': 'emotet'
    }
    
    # Threat intelligence sources (simulated)
    THREAT_SOURCES = [
        'VirusTotal', 'Hybrid Analysis', 'Malware Bazaar', 'ThreatFox',
        'URLVoid', 'AlienVault OTX', 'IBM X-Force', 'Cisco Talos'
    ]
    
    # Malware families and their characteristics
    MALWARE_FAMILIES = {
        'wannacry': {
            'type': 'ransomware',
            'severity': 'critical',
            'description': 'WannaCry ransomware that exploits SMB vulnerabilities'
        },
        'conficker': {
            'type': 'worm',
            'severity': 'high',
            'description': 'Conficker worm that spreads via network shares'
        },
        'zeus': {
            'type': 'banking_trojan',
            'severity': 'high', 
            'description': 'Zeus banking trojan for credential theft'
        },
        'emotet': {
            'type': 'trojan',
            'severity': 'high',
            'description': 'Emotet trojan and malware dropper'
        }
    }
    
    def __init__(self):
        pass
    
    def validate_hash(self, hash_value: str) -> HashValidation:
        """Validate hash format and detect hash type"""
        
        hash_value = hash_value.strip().lower()
        hash_length = len(hash_value)
        issues = []
        detected_type = "unknown"
        is_valid = False
        
        # Check for valid hexadecimal characters
        if not re.match(r'^[a-fA-F0-9]+$', hash_value):
            issues.append("Hash contains invalid characters (not hexadecimal)")
        
        # Detect hash type based on length
        for hash_type, pattern in self.HASH_PATTERNS.items():
            if re.match(pattern, hash_value):
                detected_type = hash_type
                is_valid = True
                break
        
        if not is_valid:
            issues.append(f"Invalid hash length: {hash_length} characters")
            if hash_length not in [32, 40, 64, 128]:
                issues.append("Hash length doesn't match common algorithms (MD5, SHA1, SHA256, SHA512)")
        
        return HashValidation(
            is_valid_hash=is_valid,
            detected_hash_type=detected_type,
            hash_length=hash_length,
            hash_format_issues=issues
        )
    
    def check_known_malicious(self, hash_value: str) -> Optional[str]:
        """Check if hash is in known malicious samples"""
        return self.KNOWN_MALICIOUS_HASHES.get(hash_value.lower())
    
    async def _check_virustotal_api(self, hash_value: str) -> Optional[ThreatIntelligenceResult]:
        """Check hash against VirusTotal API"""
        import os
        import aiohttp
        
        api_key = os.getenv('VIRUSTOTAL_API_KEY')
        if not api_key:
            return None
        
        try:
            url = "https://www.virustotal.com/vtapi/v2/file/report"
            params = {
                'apikey': api_key,
                'resource': hash_value
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('response_code') != 1:
                            return None
                        
                        positives = data.get('positives', 0)
                        total = data.get('total', 0)
                        
                        # Extract malware family from scan results
                        malware_family = None
                        if positives > 0:
                            scans = data.get('scans', {})
                            for engine_result in scans.values():
                                if engine_result.get('detected'):
                                    detection = engine_result.get('result', '').lower()
                                    for family in self.MALWARE_FAMILIES.keys():
                                        if family in detection:
                                            malware_family = family
                                            break
                                    if malware_family:
                                        break
                        
                        return ThreatIntelligenceResult(
                            source_name="VirusTotal",
                            is_malicious=positives > 0,
                            detection_ratio=f"{positives}/{total}",
                            threat_type="malware" if positives > 0 else None,
                            malware_family=malware_family,
                            confidence_score=min(95, (positives / total * 100)) if total > 0 else 0,
                            last_seen=data.get('scan_date'),
                            scan_date=datetime.now(timezone.utc)
                        )
        except Exception as e:
            print(f"VirusTotal API error: {e}")
        
        return None
    
    async def _check_hybrid_analysis_api(self, hash_value: str) -> Optional[ThreatIntelligenceResult]:
        """Check hash against Hybrid Analysis API"""
        import os
        import aiohttp
        
        api_key = os.getenv('HYBRID_ANALYSIS_API_KEY')
        if not api_key:
            return None
        
        try:
            url = "https://www.hybrid-analysis.com/api/v2/search/hash"
            headers = {
                'api-key': api_key,
                'user-agent': 'Falcon Sandbox'
            }
            data = {'hash': hash_value}
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, data=data, timeout=10) as response:
                    if response.status == 200:
                        results = await response.json()
                        
                        if not results:
                            return None
                        
                        # Process first result
                        result = results[0] if results else {}
                        verdict = result.get('verdict', '').lower()
                        is_malicious = verdict in ['malicious', 'suspicious']
                        
                        return ThreatIntelligenceResult(
                            source_name="Hybrid Analysis",
                            is_malicious=is_malicious,
                            detection_ratio="1/1" if is_malicious else "0/1",
                            threat_type=result.get('type_short'),
                            malware_family=result.get('family'),
                            confidence_score=85 if is_malicious else 15,
                            last_seen=result.get('submit_time'),
                            scan_date=datetime.now(timezone.utc)
                        )
        except Exception as e:
            print(f"Hybrid Analysis API error: {e}")
        
        return None
    
    async def _check_malware_bazaar_api(self, hash_value: str) -> Optional[ThreatIntelligenceResult]:
        """Check hash against Malware Bazaar API"""
        import aiohttp
        
        try:
            url = "https://mb-api.abuse.ch/api/v1/"
            data = {
                'query': 'get_info',
                'hash': hash_value
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=data, timeout=10) as response:
                    if response.status == 200:
                        result = await response.json()
                        
                        if result.get('query_status') != 'ok':
                            return None
                        
                        data_info = result.get('data', [])
                        if not data_info:
                            return None
                        
                        sample = data_info[0]
                        
                        return ThreatIntelligenceResult(
                            source_name="Malware Bazaar",
                            is_malicious=True,  # If found in MB, it's malicious
                            detection_ratio="1/1",
                            threat_type=sample.get('file_type'),
                            malware_family=sample.get('signature'),
                            confidence_score=90,
                            last_seen=sample.get('first_seen'),
                            scan_date=datetime.now(timezone.utc)
                        )
        except Exception as e:
            print(f"Malware Bazaar API error: {e}")
        
        return None
    
    def generate_real_malware_metadata(self, hash_value: str, malware_family: Optional[str], 
                                     threat_results: List[ThreatIntelligenceResult]) -> Optional[MalwareMetadata]:
        """Generate malware metadata from real threat intelligence results"""
        
        if not malware_family and not any(r.is_malicious for r in threat_results):
            return None
        
        # Extract real data from threat intelligence results
        detection_names = []
        for result in threat_results:
            if result.is_malicious:
                detection_names.append(f"{result.source_name}:{result.threat_type or 'malware'}")
        
        # Use family info if available
        family_info = self.MALWARE_FAMILIES.get(malware_family, {}) if malware_family else {}
        
        # Build metadata from real sources where possible
        file_names = [f"{hash_value[:8]}.bin"]  # Conservative filename
        if malware_family:
            file_names.append(f"{malware_family}.exe")
        
        # Conservative behavioral analysis based on family type
        file_type = family_info.get('type', 'unknown')
        behavioral_analysis = {
            "network_activity": file_type in ['trojan', 'banking_trojan'],
            "file_modifications": 1 if any(r.is_malicious for r in threat_results) else 0,
            "registry_modifications": 1 if file_type in ['trojan', 'worm'] else 0,
            "processes_created": 1 if file_type == 'trojan' else 0,
            "mutex_created": file_type in ['trojan', 'worm'],
            "persistence_mechanisms": 1 if file_type in ['trojan', 'worm'] else 0
        }
        
        return MalwareMetadata(
            file_names=file_names,
            file_size=0,  # Unknown without file analysis
            file_type="Unknown",  # Would need file analysis
            first_seen=datetime.now(timezone.utc) - timedelta(days=30),  # Conservative estimate
            detection_names=detection_names,
            yara_rules=[],  # Would need YARA rule database
            behavioral_analysis=behavioral_analysis,
            network_indicators=[],  # Would need dynamic analysis
            file_indicators=[],  # Would need static analysis
            iocs=[]  # Would need IOC extraction
        )
    
    def analyze_reputation(self, threat_results: List[ThreatIntelligenceResult]) -> ReputationAnalysis:
        """Analyze file reputation based on threat intelligence results"""
        
        total_vendors = len(threat_results)
        vendor_detections = sum(1 for result in threat_results if result.is_malicious)
        
        # Calculate trust score
        if vendor_detections == 0:
            trust_score = 95.0
        elif vendor_detections <= total_vendors * 0.1:  # Less than 10% detection
            trust_score = 70.0
        elif vendor_detections <= total_vendors * 0.3:  # Less than 30% detection
            trust_score = 40.0
        elif vendor_detections <= total_vendors * 0.6:  # Less than 60% detection
            trust_score = 20.0
        else:  # High detection rate
            trust_score = 5.0
        
        # Determine reputation level
        if trust_score >= 80:
            reputation_level = "trusted"
        elif trust_score >= 60:
            reputation_level = "neutral"
        elif trust_score >= 30:
            reputation_level = "suspicious"
        else:
            reputation_level = "malicious"
        
        # Calculate community votes based on vendor detections
        if reputation_level == "malicious":
            # High detection ratio suggests strong community consensus for malicious
            community_votes = {
                "malicious": min(200, vendor_detections * 3 + 50),
                "harmless": max(0, 10 - vendor_detections)
            }
        elif reputation_level == "suspicious":
            # Medium detection suggests mixed community opinion
            community_votes = {
                "malicious": min(50, vendor_detections * 2 + 10),
                "harmless": min(30, 20 + (10 - vendor_detections))
            }
        else:
            # Low/no detection suggests community views as harmless
            community_votes = {
                "malicious": max(0, vendor_detections),
                "harmless": min(100, 30 + (20 - vendor_detections))
            }
        
        return ReputationAnalysis(
            trust_score=trust_score,
            reputation_level=reputation_level,
            vendor_detections=vendor_detections,
            total_vendors=total_vendors,
            community_votes=community_votes
        )
    
    def calculate_overall_verdict(self, reputation: ReputationAnalysis, 
                                 threat_results: List[ThreatIntelligenceResult]) -> Tuple[str, float]:
        """Calculate overall verdict and risk score"""
        
        # Count malicious detections
        malicious_count = sum(1 for result in threat_results if result.is_malicious)
        total_sources = len(threat_results)
        
        # Calculate risk score
        risk_score = 0
        
        if malicious_count > 0:
            detection_rate = malicious_count / total_sources
            risk_score = detection_rate * 100
            
            # Boost score based on confidence
            avg_confidence = sum(result.confidence_score for result in threat_results 
                               if result.is_malicious) / malicious_count
            risk_score = (risk_score + avg_confidence) / 2
        
        # Determine verdict
        if risk_score >= 70:
            verdict = "malicious"
        elif risk_score >= 30:
            verdict = "suspicious"
        else:
            verdict = "clean"
        
        return verdict, risk_score
    
    def generate_recommendations(self, verdict: str, risk_score: float, 
                               reputation: ReputationAnalysis) -> List[str]:
        """Generate security recommendations"""
        recommendations = []
        
        if verdict == "malicious":
            recommendations.extend([
                "URGENT: This file is identified as malware - DO NOT EXECUTE",
                "Quarantine or delete the file immediately",
                "Scan your system for additional malware",
                "Check if this file has already been executed on your system",
                "Report the hash to your security team",
                "Consider incident response procedures"
            ])
        elif verdict == "suspicious":
            recommendations.extend([
                "Exercise caution - file has suspicious characteristics",
                "Do not execute without thorough analysis",
                "Consider dynamic analysis in a sandbox environment",
                "Verify file source and legitimacy",
                "Monitor system if file was already executed"
            ])
        else:
            recommendations.extend([
                "File appears clean but continue monitoring",
                "Verify file source if obtained from untrusted location",
                "Keep antivirus definitions updated"
            ])
        
        # General recommendations
        recommendations.extend([
            "Maintain updated antivirus/anti-malware software",
            "Use application whitelisting where possible",
            "Implement defense-in-depth security measures",
            "Regular security awareness training for users"
        ])
        
        return recommendations
    
    async def check_hash(self, hash_value: str, check_multiple_sources: bool = True,
                        include_metadata: bool = True) -> Dict[str, Any]:
        """Perform comprehensive hash analysis using real threat intelligence"""
        
        # Validate hash
        hash_validation = self.validate_hash(hash_value)
        if not hash_validation.is_valid_hash:
            raise ValueError("Invalid hash format")
        
        # Check against real threat intelligence sources
        threat_results = []
        
        # Try VirusTotal first
        vt_result = await self._check_virustotal_api(hash_value)
        if vt_result:
            threat_results.append(vt_result)
        
        # Try other sources if multiple sources requested
        if check_multiple_sources:
            hybrid_result = await self._check_hybrid_analysis_api(hash_value)
            if hybrid_result:
                threat_results.append(hybrid_result)
            
            malware_bazaar_result = await self._check_malware_bazaar_api(hash_value)
            if malware_bazaar_result:
                threat_results.append(malware_bazaar_result)
        
        # If no real API results, provide safe default
        if not threat_results:
            threat_results.append(ThreatIntelligenceResult(
                source_name="No APIs configured",
                is_malicious=False,
                detection_ratio="0/0",
                threat_type=None,
                malware_family=None,
                confidence_score=0,
                last_seen=None,
                scan_date=datetime.now(timezone.utc)
            ))
        
        # Check for known malicious samples (local database)
        malware_family = self.check_known_malicious(hash_value)
        
        # Generate metadata if malicious
        malware_metadata = None
        if include_metadata and (malware_family or any(r.is_malicious for r in threat_results)):
            detected_family = malware_family or next(
                (r.malware_family for r in threat_results if r.malware_family), None
            )
            malware_metadata = self.generate_real_malware_metadata(hash_value, detected_family, threat_results)
        
        # Analyze reputation
        reputation = self.analyze_reputation(threat_results)
        
        # Calculate overall verdict
        verdict, risk_score = self.calculate_overall_verdict(reputation, threat_results)
        
        # Generate recommendations
        recommendations = self.generate_recommendations(verdict, risk_score, reputation)
        
        return {
            'hash_validation': hash_validation,
            'threat_results': threat_results,
            'malware_metadata': malware_metadata,
            'reputation': reputation,
            'verdict': verdict,
            'risk_score': risk_score,
            'recommendations': recommendations
        }


async def execute_tool(input_data: MalwareHashInput) -> MalwareHashOutput:
    """Execute the malware hash checker tool"""
    
    try:
        checker = MalwareHashChecker()
        
        # Perform hash analysis
        results = await checker.check_hash(
            input_data.hash_value,
            input_data.check_multiple_sources,
            input_data.include_metadata
        )
        
        return MalwareHashOutput(
            success=True,
            hash_value=input_data.hash_value,
            hash_validation=results['hash_validation'],
            threat_intelligence=results['threat_results'],
            malware_metadata=results['malware_metadata'],
            reputation_analysis=results['reputation'],
            overall_verdict=results['verdict'],
            risk_score=results['risk_score'],
            recommendations=results['recommendations'],
            analysis_timestamp=datetime.now(timezone.utc)
        )
        
    except Exception as e:
        return MalwareHashOutput(
            success=False,
            hash_value=input_data.hash_value,
            hash_validation=HashValidation(
                is_valid_hash=False,
                detected_hash_type="unknown",
                hash_length=len(input_data.hash_value),
                hash_format_issues=[str(e)]
            ),
            threat_intelligence=[],
            malware_metadata=None,
            reputation_analysis=ReputationAnalysis(
                trust_score=0.0,
                reputation_level="unknown",
                vendor_detections=0,
                total_vendors=0,
                community_votes={}
            ),
            overall_verdict="unknown",
            risk_score=0.0,
            recommendations=[],
            analysis_timestamp=datetime.now(timezone.utc),
            error=str(e)
        )


# Tool metadata
TOOL_INFO = {
    "name": "malware_hash_checker",
    "display_name": "Malware Hash Checker",
    "description": "Check file hashes against threat intelligence sources and malware databases",
    "version": "1.0.0",
    "author": "Wildbox Security",
    "category": "malware_analysis"
}


# For testing
if __name__ == "__main__":
    import asyncio
    
    async def test():
        # Test with known malicious hash
        test_input = MalwareHashInput(
            hash_value="84c82835a5d21bbcf75a61706d8ab549",  # WannaCry sample
            check_multiple_sources=True,
            include_metadata=True
        )
        
        result = await execute_tool(test_input)
        print(f"Hash Check Success: {result.success}")
        print(f"Hash: {result.hash_value}")
        print(f"Hash Type: {result.hash_validation.detected_hash_type}")
        print(f"Overall Verdict: {result.overall_verdict}")
        print(f"Risk Score: {result.risk_score}")
        print(f"Vendor Detections: {result.reputation_analysis.vendor_detections}/{result.reputation_analysis.total_vendors}")
        
        if result.malware_metadata:
            print(f"Malware Family: {result.threat_intelligence[0].malware_family if result.threat_intelligence else 'Unknown'}")
    
    asyncio.run(test())
